{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import os\n",
    "from scipy.stats import friedmanchisquare\n",
    "from scipy.stats import chi2\n",
    "\n",
    "# change to your local path to project below\n",
    "project_path = '/home/jorge/Insync/jorgitoje@gmail.com/OneDrive/Documentos/JORGE/EDUCATION/MASTER_DATASCIENCE/Semester1/AdvancedStatistics/GroupProject/KDS_Statistics_GroupProject'\n",
    "# TO DO:\n",
    "# - Include CART method when already having data correct\n",
    "# - Add tie correction to W\n",
    "# -  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>feature_name</th>\n",
       "      <th colspan=\"4\" halign=\"left\">feature_rank</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Linear_regression</th>\n",
       "      <th>Random_forest</th>\n",
       "      <th>Ridge_regression</th>\n",
       "      <th>elastic_net</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Airbnb_price</td>\n",
       "      <td>accommodates</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Airbnb_price</td>\n",
       "      <td>amenities</td>\n",
       "      <td>16.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Airbnb_price</td>\n",
       "      <td>bathrooms</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Airbnb_price</td>\n",
       "      <td>bed_type</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Airbnb_price</td>\n",
       "      <td>bedrooms</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             dataset  feature_name      feature_rank                \\\n",
       "method                             Linear_regression Random_forest   \n",
       "0       Airbnb_price  accommodates               5.0           7.0   \n",
       "1       Airbnb_price     amenities              16.5           5.0   \n",
       "2       Airbnb_price     bathrooms               2.0           3.0   \n",
       "3       Airbnb_price      bed_type              13.0          17.0   \n",
       "4       Airbnb_price      bedrooms               3.0           8.0   \n",
       "\n",
       "                                     \n",
       "method Ridge_regression elastic_net  \n",
       "0                   5.0         4.0  \n",
       "1                  16.5        13.0  \n",
       "2                   2.0         3.0  \n",
       "3                  13.0        14.0  \n",
       "4                   3.0         2.0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featureranks_basepath = os.path.join(project_path, 'data')\n",
    "all_ranks_all_methods_long = pd.DataFrame()\n",
    "\n",
    "# Put all ranks into one csv\n",
    "for file in os.listdir(featureranks_basepath):\n",
    "    if file.endswith('.csv') and file != 'featureranks_ALLMETHODS.csv':\n",
    "        df = pd.read_csv(os.path.join(featureranks_basepath, file), sep=\";\")\n",
    "        all_ranks_all_methods_long = pd.concat([all_ranks_all_methods_long, df], axis=0)\n",
    "\n",
    "# Save all ranks together\n",
    "all_ranks_all_methods_long.to_csv(os.path.join(project_path, 'data', 'featureranks_ALLMETHODS.csv'), sep=\";\", index=False)\n",
    "all_ranks_all_methods_long = all_ranks_all_methods_long.query('method != \"CART\" and method != \"Lasso_regression\"') # temporarily take out these methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "method             dataset             \n",
       "Linear_regression  Airbnb_price            18\n",
       "                   Bike_sharing            12\n",
       "                   USA_houseprices_2014    13\n",
       "                   austin_housing          27\n",
       "                   cars                    34\n",
       "Random_forest      Airbnb_price            18\n",
       "                   Bike_sharing            12\n",
       "                   USA_houseprices_2014    13\n",
       "                   austin_housing          27\n",
       "                   cars                    34\n",
       "Ridge_regression   Airbnb_price            18\n",
       "                   Bike_sharing            12\n",
       "                   USA_houseprices_2014    13\n",
       "                   austin_housing          27\n",
       "                   cars                    34\n",
       "elastic_net        Airbnb_price            18\n",
       "                   Bike_sharing            12\n",
       "                   USA_houseprices_2014    13\n",
       "                   austin_housing          27\n",
       "                   cars                    34\n",
       "Name: feature_name, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ranks_all_methods_long.query('method != \"CART\" and method != \"Lasso_regression\"').groupby(['method', 'dataset'])['feature_name'].count()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kendall's W"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using friedmanchisquare\n",
    "(DOES NOT seem to work and requires manually putting all columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# spRes = friedmanchisquare(data_kendall['PCA'].to_numpy(), data_kendall['RandomForest'].to_numpy(), data_kendall['linear_regression'].to_numpy())\n",
    "# spRes = friedmanchisquare(*[data_kendall[column] for column in data_kendall.columns])\n",
    "# friedmanchisquare()\n",
    "# selData()\n",
    "# n = data_kendall.shape[0]\n",
    "# k = data_kendall.shape[1]\n",
    "# Q = spRes[0]\n",
    "# print(f\"n: {n},k: {k}, Q: {Q}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# W = Q / (n*(k-1))\n",
    "# print(f\"W: {W}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using direct formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_kendallW(data_kendall, tie_correction=False):\n",
    "    '''_summary_\n",
    "\n",
    "    Args:\n",
    "        data_kendall (pd.dataframe): Datafrem containing as columns the feature\n",
    "        selection methods and as values ranks to each feature in the same order.\n",
    "\n",
    "    Returns:\n",
    "        W: Kendall's W coefficient\n",
    "    '''\n",
    "    n = data_kendall.shape[0] # number of features/objects\n",
    "    k = data_kendall.shape[1] # numbe of raters/methods\n",
    "\n",
    "    # Sum of each item ranks\n",
    "    sums = data_kendall.sum(axis=1, numeric_only=True).to_numpy()\n",
    "    # Mean of ranking sums\n",
    "    Rbar = sums.mean()\n",
    "    Rbar\n",
    "    # Sum of squared deviations from the mean\n",
    "    S = np.sum([(np.array(sums)[x] - Rbar) ** 2 for x in range(n)])\n",
    "    if not tie_correction:\n",
    "        W = (12 * S) / (k ** 2 * (n ** 3 - n))\n",
    "    else:\n",
    "        # TO DO: implement tie correction\n",
    "        T=3 \n",
    "        numerator = 12*np.sum([np.array(sums)[x] for x in range(n)]) - 3*(k**2)*n*(n+1)**2\n",
    "        print(numerator)\n",
    "        denominator = ((k**2)*n*(n**2 - 1) - k*T)\n",
    "        W = numerator /  denominator\n",
    "        return None\n",
    "\n",
    "    return W"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topâ€“k overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_topkoverlap(datatopk, k=5):\n",
    "\n",
    "    data_all = datatopk.copy(deep=True)\n",
    "\n",
    "    n = len(data_all)\n",
    "\n",
    "    assert len(data_all) >= k, f\"Maximum value for k is {n}, which is total number of features\"\n",
    "\n",
    "    methods = data_all.columns.to_list()\n",
    "    data_all['feature_id'] = data_all.index\n",
    "\n",
    "    all_toplists = []\n",
    "\n",
    "    for method in methods:\n",
    "        data_temp = data_all.filter(items=['feature_id', method]) \\\n",
    "            .sort_values(method).head(k)['feature_id'].to_list()\n",
    "        all_toplists.append(data_temp)\n",
    "    union_lists= np.unique(all_toplists)\n",
    "    intersection_lists = set.intersection(*map(set, all_toplists))\n",
    "\n",
    "    topk_overlap = len(intersection_lists)/len(union_lists)\n",
    "        \n",
    "    return topk_overlap\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis testing for all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS FOR DATASET 'USA_houseprices_2014'\n",
      "There are 13 features and 4 raters\n",
      "Kendall's W: 0.5675718512256974\n",
      "Top-5 overlap: 0.1111111111111111\n",
      "Top-10 overlap: 0.5384615384615384\n",
      "Statistic value(alpha=0.05): 27.243448858833474\n",
      "Chi2 (alpha=0.05, 12 dof): 5.226029488392639\n",
      "We reject null hypothesis and conclude that H1: W â‰  0.\n",
      "-------------------------------------------------------------------\n",
      "RESULTS FOR DATASET 'Bike_sharing'\n",
      "There are 12 features and 4 raters\n",
      "Kendall's W: 0.7801209207459208\n",
      "Top-5 overlap: 0.6666666666666666\n",
      "Top-10 overlap: 0.6666666666666666\n",
      "Statistic value(alpha=0.05): 34.32532051282051\n",
      "Chi2 (alpha=0.05, 11 dof): 4.574813079322224\n",
      "We reject null hypothesis and conclude that H1: W â‰  0.\n",
      "-------------------------------------------------------------------\n",
      "RESULTS FOR DATASET 'Airbnb_price'\n",
      "There are 18 features and 4 raters\n",
      "Kendall's W: 0.5490769407178075\n",
      "Top-5 overlap: 0.2222222222222222\n",
      "Top-10 overlap: 0.3333333333333333\n",
      "Statistic value(alpha=0.05): 37.33723196881091\n",
      "Chi2 (alpha=0.05, 17 dof): 8.671760204670077\n",
      "We reject null hypothesis and conclude that H1: W â‰  0.\n",
      "-------------------------------------------------------------------\n",
      "RESULTS FOR DATASET 'austin_housing'\n",
      "There are 27 features and 4 raters\n",
      "Kendall's W: 0.6779863654863654\n",
      "Top-5 overlap: 0.25\n",
      "Top-10 overlap: 0.25\n",
      "Statistic value(alpha=0.05): 70.510582010582\n",
      "Chi2 (alpha=0.05, 26 dof): 15.379156583261723\n",
      "We reject null hypothesis and conclude that H1: W â‰  0.\n",
      "-------------------------------------------------------------------\n",
      "RESULTS FOR DATASET 'cars'\n",
      "There are 34 features and 4 raters\n",
      "Kendall's W: 0.15255920550038196\n",
      "Top-5 overlap: 0.0\n",
      "Top-10 overlap: 0.0\n",
      "Statistic value(alpha=0.05): 20.13781512605042\n",
      "Chi2 (alpha=0.05, 33 dof): 20.86653399071479\n",
      "We cannot reject null hypothesis H0: W = 0\n",
      "-------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for dataset_name in all_ranks_all_methods_long['dataset'].unique():\n",
    "\n",
    "    # Transform to long for better manipulation\n",
    "    data_ranks_wide = all_ranks_all_methods_long.query('dataset == @dataset_name').pivot( index=['dataset', 'feature_name'], columns=['method'], \n",
    "        values=['feature_rank']).reset_index()\n",
    "    data_ranks_wide.head()\n",
    "\n",
    "    data_kendall = data_ranks_wide['feature_rank'].astype(int)\n",
    "\n",
    "\n",
    "    W = calculate_kendallW(data_kendall, tie_correction=False)\n",
    "    top5_overlap = calculate_topkoverlap(data_kendall, k=5)\n",
    "    top10_overlap = calculate_topkoverlap(data_kendall, k=10)\n",
    "\n",
    "    n = data_kendall.shape[0]\n",
    "    k = data_kendall.shape[1]\n",
    "\n",
    "    alpha = 0.05\n",
    "    degrees_of_freedom = n - 1\n",
    "    chisquared_alpha = chi2.ppf(q = alpha, df = degrees_of_freedom)\n",
    "    chisquared_statistic = k *(n-1) * W\n",
    "\n",
    "    print(f\"RESULTS FOR DATASET '{dataset_name}'\")\n",
    "    print(f\"There are {n} features and {k} raters\")\n",
    "    print(f\"Kendall's W: {W}\")\n",
    "    print(f\"Top-5 overlap: {top5_overlap}\")\n",
    "    print(f\"Top-10 overlap: {top10_overlap}\")\n",
    "    print(f\"Statistic value(alpha={alpha}): {chisquared_statistic}\")\n",
    "    print(f\"Chi2 (alpha={alpha}, {degrees_of_freedom} dof): {chisquared_alpha}\") # Tabled value\n",
    "\n",
    "    if chisquared_statistic >= chisquared_alpha:\n",
    "        print(\"We reject null hypothesis and conclude that H1: W â‰  0.\")\n",
    "    else:\n",
    "        print(\"We cannot reject null hypothesis H0: W = 0\")\n",
    "    \n",
    "    print('-------------------------------------------------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f32660438fc59d2700eb141444e309afef4ae66632a8cd2414f796115374bfa4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
